---
title: "Veri Tipi Belirleme"
author: "BÃ¼kra DoÄŸaner"
date: '2022-03-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ã§alÄ±ÅŸacaÄŸÄ±mÄ±z verisetinin iÃ§eri aktarÄ±lmasÄ± iÃ§in `read.csv`` fonksiyonu kullanÄ±lÄ±r. 
iÃ§eri aktarcaÄŸÄ±mÄ±z lokal dosya yolu yada uzak sunucuda tutulan dosyanÄ±n yolu fonksiyona girdi olarak verilir. 

```{r}
veriseti <- read.csv("fin500.csv")
```

veriseti yÃ¼klendikten sonra veriseti iÃ§eriÄŸini kontrol etmek Ã¼zere `head()` ve `tail()` fonksiyonlarÄ± kullanÄ±lÄ±r


```{r}
head(veriseti,15)

tail(veriseti,2) 
```
verisetinde yer alan datalarÄ±n yapÄ±sÄ±nÄ± gÃ¶rmek iÃ§in str fonksiyonu kullanÄ±lÄ±r

```{r}
str(veriseti) 
```

Veriseti iÃ§indeki tek bir stÃ¼nÃ¼n okunmasÄ± iÃ§in veriseti$xx komutu kullanÄ±lÄ±r. Ã–rnek olarak Industry stÃ¼nunun gÃ¶rÃ¼ntÃ¼lenmesi iÃ§in 

```{r}
veriseti$Industry
```

Verisetine dair Ã¶zet bilgi iÃ§in summary() fonksiyonu kullanÄ±lÄ±r.

```{r}
summary(veriseti) 
```

verisetinde yer alan verilerin yapÄ±sÄ±nÄ±n deÄŸiÅŸtirilmesi iÃ§in veriseti$() <- as.factor(veriseti$veriseti$deÄŸiÅŸiklik yapÄ±lacak sÃ¼tun) fonksiyonu kullanÄ±lÄ±r. Verilerin doÄŸru analiz edilmesi iÃ§in verisetinde yer alan bilgilerin doÄŸru ÅŸekilde tanÄ±mlanmasÄ± gerekmektedir. TÃ¼m veriler tek tek incelenerek tanÄ±mlamasÄ± yapÄ±lmalÄ±dÄ±r.

```{r}
veriseti$Industry <- as.factor(veriseti$Industry)
veriseti$Inception <- as.factor(veriseti$Inception)
veriseti$State <- as.factor(veriseti$State)
veriseti$City <- as.factor(veriseti$City)
veriseti$Revenue <- as.character(veriseti$Revenue)
```

Verilerin istenilen formata uygun olmasÄ± iÃ§in _veri temizliÄŸi_ iÅŸlemi yapÄ±lmalÄ±dÄ±r. Bu iÅŸlemde gsub() komutu kullanÄ±labilmektedir. Verilerin rakamsal veri olarak algÄ±lanmasÄ± iÃ§in sayÄ±larÄ±n sonunda yer alan dolar kelimesinin silinmesi fonksiyonu aÅŸaÄŸÄ±daki gibidir. gsub("Ã§Ä±karÄ±lmasÄ± gereken deÄŸer", "yerine konulacak deÄŸer", veriseti$deÄŸiÅŸiklik yapÄ±lacak sÃ¼tun)

```{r}
veriseti$Expenses <- gsub(" Dollars", "", veriseti$Expenses)
veriseti$Expenses <- gsub(",", "", veriseti$Expenses) 
``` 

iÅŸlem kalabalÄ±ÄŸÄ± olmamasÄ± aÃ§Ä±sÄ±ndan gsub fonksiyonunun kullanÄ±ldÄ±ÄŸÄ± iÅŸlemi aÅŸaÄŸÄ±daki ÅŸekilde birleÅŸtirmek mÃ¼mkÃ¼ndÃ¼r. 

```{r}
veriseti$Growth <- as.numeric(gsub("%", "", veriseti$Growth))
``` 

Verilerde yer alan $ gibi R programÄ±nda bir anlam ifade eden karakterlerle ilgili iÅŸlem yapÄ±lacaÄŸÄ± zaman baÅŸÄ±na "\\" koyularak karakterin programda bir anlam ifade etmediÄŸi tanÄ±mlanÄ±r.

```{r}
veriseti$Revenue <- gsub("\\$","", veriseti$Revenue)
``` 



## Normalizasyon Ä°ÅŸlemleri

### Parametreler kullanÄ±larak verisetinin dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi


_Scale YÃ¶ntemi_

$$  
\frac{X{i}}{\sigma{x}}
$$

_Center YÃ¶ntemi_

$$
x{i}-\bar{X}_{x}
$$

__Range Normalizasyon__

$$
\frac{x_{i}-\mu_{x}}{\sigma_{x}}
$$


## Cross Validation

Bootstrap yÃ¶ntemi ile 100 verilik Ã¶rneklem oluÅŸturduk. 

```{r}
train_control <- trainControl(method="boot", number = 100)
```

### test/ split method

library(caret)

data(iris)

Test ve train bÃ¶lÃ¼m oranÄ±nÄ± belirlenir
```{r} 
split=0.80
```

Train iÃ§in kullanÄ±lacak veriler %80'lik kÄ±sÄ±mÄ± oluÅŸturmaktadÄ±r. Bu veriler trainIndex olarak tanÄ±mlanmÄ±ÅŸtÄ±r

```{r}
data_train <- iris[trainIndex,]  
data_train <- iris[-trainIndex,]  
```

### Leave one out cross validation LOOCV 

library(caret)
data(iris)

__define training cont__

```{r}
train_control <- trainControl(method = "LOOCV")
```

### K-Fold Cross Validation


__k fold number -> number__

```{r}
train_control <- trainControl(method="cv", number=10)
```

### Repeated Cross Validation

```{r}
train_control <- trainControl(method = "repeatedcv" , number=10, repeats=3)
```

# Regresyon Analizi

1. Rastgele seÃ§ilecek Ã¶rneklemleri sabit bir sayÄ±da tutabilmek iÃ§in 'seed' sayÄ±sÄ± belirlenir. Bunun iÃ§in aÅŸaÄŸÄ±da belirtilen komut kullanÄ±lÄ±r.

```{r}
set.seed(...)
```

2. Verisetinin train ve test olarak parÃ§alanmasÄ± iÃ§in gerekli komutlar girilir. ParÃ§alanma oranÄ± ve veriler bu komutta belirtilir. Uygulamada kullanÄ±lan verisetinde parÃ§alama oranÄ± %75'tir.

```{r}
sample_size <- floor(0.75 * nrow(Boston))
```

3. Train ve test verilerinin tanÄ±mlanmasÄ± yapÄ±lÄ±r.

```{r}
train <- Boston[training_index, ]
test <- Boston[-training_index, ]
```

## Ridge Regresyon


Ã‡ok deÄŸiÅŸkenli regresyon verilerini analiz etmede kullanÄ±lmaktadÄ±r. AmaÃ§ hata kareler toplamÄ±nÄ± minimize eden katsayÄ±larÄ±, bu katsayÄ±lara bir ceza uygulayarak bulmaktÄ±r. Over-fittinge karÅŸÄ± direnÃ§lidir. Ã‡ok boyutluluÄŸa Ã§Ã¶zÃ¼m sunar. TÃ¼m deÄŸiÅŸkenler ile model kurar, ilgisiz deÄŸiÅŸkenleri Ã§Ä±karmaz sadece katsayÄ±larÄ±nÄ± sÄ±fÄ±ra yaklaÅŸtÄ±rÄ±r. Modeli kurarken alpha (ceza) iÃ§in iyi bir deÄŸer bulmak gerekir.

AÅŸaÄŸÄ±da Ridge Regresyon Ã§Ã¶zÃ¼mÃ¼ iÃ§in uygulama Ã¶rneÄŸi verilmiÅŸtir. Ã–rnek Ã§Ã¶zÃ¼mde Alfa katsayÄ±sÄ± 0 olarak belirtilmiÅŸtir. X baÄŸÄ±msÄ±z deÄŸiÅŸken, Y ise baÄŸÄ±mlÄ± deÄŸiÅŸkendir.
```{r}
cv.r <- cv.glmnet(x, y, alpha = 0)
```

Daha sonra CV ile lambda'nÄ±n minimum deÄŸeri belirlenmiÅŸtir.
```{r}
cv.r$lambda.min
```

ArdÄ±ndan lambda'nÄ±n minimum deÄŸeri modele girdi olarak eklenmiÅŸtir. 
```{r}
model.ridge <- glmnet(x, y, alpha = 0, lambda = cv.r$lambda.min)
```

Modelin coefficient deÄŸerlerine bakÄ±lmÄ±ÅŸtÄ±r.
```{r}
coef(model.ridge)
```

Daha sonra test verisi oluÅŸturduk ve oluÅŸturulan test verisi ile predict deÄŸerleri kullanÄ±lmÄ±ÅŸtÄ±r. Bulunan sonuÃ§lar vektÃ¶r olarak kullanÄ±lmÄ±ÅŸtÄ±r.
```{r}
x.test.ridge <- model.matrix(medv ~., test)[,-1]
predictions.ridge <- model.ridge %>% predict(x.test.ridge) %>% as.vector()
```

Predict deÄŸerleri ile modelde elde edilen verilerin kÄ±yaslanmasÄ± iÃ§in RMSE komutu kullanÄ±lmaktadÄ±r. BÃ¶ylece regresyonda elde edilen sonucun saÄŸlamasÄ± yapÄ±lacaktÄ±r.

```{r}
data.frame( RMSE.r = RMSE(predictions.ridge, test$medv), Rsquare.r = R2(predictions.ridge, test$medv))
```


## Lasso Regresyon Analizi

Lasso (Least Absolute Shrinkage and Selection Operator) Regresyon, en kÃ¼Ã§Ã¼k kareler(EKK) yÃ¶ntemine alternatif yanlÄ± tahmin yÃ¶ntemlerinden biridir. Lasso Regresyon, hem deÄŸiÅŸken seÃ§iminin hem de regularizasyonun aynÄ± anda gerÃ§ekleÅŸtiÄŸi bir regresyon tekniÄŸidir. Etkili ve hÄ±zlÄ± olmasÄ± nedeniyle bÃ¼yÃ¼k veri setlerinde yaygÄ±n olarak uygulanmaktadÄ±r.
EKK modelinin kurulamayacaÄŸÄ± kadar az gÃ¶zlem sayÄ±sÄ±nÄ±n olduÄŸu durumlarda, Ã§apraz doÄŸrulama ve ceza parametresi sayesinde, model kurabilmesi nedeniyle sÄ±kÃ§a kullanÄ±lmaktadÄ±r.

Lasso Regresyon; Ã¼rettiÄŸi modelin tahmin doÄŸruluÄŸunu ve yorumlanabilirliÄŸini arttÄ±rmak iÃ§in hem deÄŸiÅŸken seÃ§imi hem de regularization yapmaktadÄ±r. AmaÃ§ hata kareler toplamÄ±nÄ± minimize eden katsayÄ±larÄ±, katsayÄ±lara ceza uygularayarak bulmaktÄ±r.

Ridge Regresyon ile Lasso Regresyonâ€™nun Ã§alÄ±ÅŸma yÃ¶ntemi birbiri ile Ã§ok benzerdir. Her ikisi de bir ceza parametresi ile yanlÄ± ancak dÃ¼ÅŸÃ¼k varyanslÄ± modeller kurar. FormÃ¼llerinde ufak bir farklÄ±lÄ±k vardÄ±r. Ridge Regresyon ceza parametresi olarak lambda katsayÄ±nÄ±n karesiâ€™ni kullanÄ±r. Lasso Regresyon ise lambda katsayÄ±nÄ±n mutlak deÄŸerini kullanÄ±r.Ridge Regresyonâ€™da herhangi bir parametre sÄ±fÄ±ra eÅŸitlenmez, yani deÄŸiÅŸken seÃ§imi yapmaz. Lasso Regresyon bu Ã¶zelliÄŸi ile daha sade ve yorumlanabilir modeller sunar.


AÅŸaÄŸÄ±da Ridge Regresyon Ã§Ã¶zÃ¼mÃ¼ iÃ§in uygulama Ã¶rneÄŸi verilmiÅŸtir. Ã–rnek Ã§Ã¶zÃ¼mde Alfa katsayÄ±sÄ± 1 olarak belirtilmiÅŸtir. X baÄŸÄ±msÄ±z deÄŸiÅŸken, Y ise baÄŸÄ±mlÄ± deÄŸiÅŸkendir.
```{r}
cv.l <- cv.glmnet(x, y, alpha = 1)
```

Ridge Regresyonda olduÄŸu gibi Ã¶nce lambda'nÄ±n minimum deÄŸeri belirlenmiÅŸtir. Daha sonra minimum deÄŸer modele eklenerek coefficient deÄŸerlerine bakÄ±lmÄ±ÅŸtÄ±r. Test ve Tahmin deÄŸerleri de belirlendikten sonra sonuÃ§larÄ±n kÄ±yaslanmasÄ± iÃ§in RMSE komutu kullanÄ±lmÄ±ÅŸtÄ±r.
```{r}
cv.l$lambda.min
model.lasso <- glmnet(x, y, alpha = 1 , lambda = cv.l$lambda.min)
coef(model.lasso)
x.test.lasso <- model.matrix(medv ~., test)[,-1] 
predictions.lasso <- model.lasso %>% predict(x.test.lasso) %>% as.vector()
data.frame( RMSE.r = RMSE(predictions.lasso, test$medv), Rsquare.r = R2(predictions.lasso, test$medv))
```

## Elastic Net Regression

Elastic Net, Ridge Regresyonu ve Lasso Regresyonu arasÄ±nda bir orta yoldur. DÃ¼zenlileÅŸtirme terimi hem Ridge hem de Lassoâ€™nun dÃ¼zenlileÅŸtirme terimlerinin basit bir karÄ±ÅŸÄ±mÄ±dÄ±r ve karÄ±ÅŸÄ±m oranÄ± ğ‘Ÿ katsayÄ±sÄ± ile kontrol edilebilmektedir. ğ‘Ÿ = 0 olduÄŸunda, Elastic Net, Ridge Regresyonuna eÅŸdeÄŸerdir ve ğ‘Ÿ = 1 olduÄŸunda ise Lasso Regresyonuna eÅŸdeÄŸerdir. Elastik Net Regresyonu, Lasso ve Ridge RegresyonlarÄ±nÄ±n gÃ¼Ã§lÃ¼ yÃ¶nlerini birleÅŸtirerek, dÃ¼zenlileÅŸtirilmiÅŸ deÄŸiÅŸkenlerle iliÅŸkili parametreleri gruplandÄ±rÄ±p kÃ¼Ã§Ã¼lterek onlarÄ± denklemde bÄ±rakmakta veya hepsini bir kerede kaldÄ±rmaktadÄ±r. Bundan dolayÄ±, birbiriyle iliÅŸkili birden fazla Ã¶zellik olduÄŸunda kullanÄ±ÅŸlÄ±dÄ±r. Lasso bunlardan sadece birini rastgele seÃ§mektedir. Elastik-net ise ikisini birden seÃ§mektedir. 

AÅŸaÄŸÄ±da dataset Ã¼zerinden bir model oluÅŸturduk.
```{r}
model.net <- train(
  medv~., data = train, method ="glmnet", 
  trControl = trainControl("cv", number=10), 
  tuneLength=10)
model.net$bestTune
```

ArdÄ±ndan oluÅŸturulan modelin coefficient deÄŸerlerine baktÄ±k.

```{r}
coef(model.net$finalModel, model.net$bestTune$lambda)
```

AlphanÄ±n yÃ¼zde 20 ridgenin yÃ¼zde 80 katkÄ±sÄ± olcak diye bulduk
```{r}
x.test.net <- model.matrix(medv ~., test)[,-1]
predictions.net <- model.net %>% predict(x.test.net)
```

Predict deÄŸerleri ile modelde elde edilen verilerin kÄ±yaslanmasÄ± iÃ§in RMSE komutu kullanÄ±lmaktadÄ±r. BÃ¶ylece regresyonda elde edilen sonucun saÄŸlamasÄ± yapÄ±lacaktÄ±r.
```{r}
data.frame( RMSE.r = RMSE(predictions.net, test$medv), Rsquare.r = R2(predictions.net, test$medv))
```

## Geleneksel Model

Klasik olarak test ve train verilerinin ayrÄ±mÄ± yapÄ±lmÄ±ÅŸtÄ±r.

```{r}
trainingRowIndex = sample(1:nrow(dataset), 0,8*nrow(dataset))
train = dataset[trainingRowIndex,2:5]
test = dataset[-trainingRowIndex, 2:5]
```

Model oluÅŸturulmuÅŸtur.
```{r}
model1 = glm(y~x1+x2, family = "binomial", data = dataset)
``` 

Modelin AIC deÄŸerinin Ã¶lÃ§Ã¼mÃ¼ iÃ§in null be deviance deÄŸerleri hesaplanmÄ±ÅŸtÄ±r. 
```{r}
ll.null = model1$null.deviance/-2 
ll.proposed = model1$deviance/-2
R2 = (ll.null - ll.proposed) / ll.null
``` 


